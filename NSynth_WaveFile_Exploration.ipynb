{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSynth Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NSynth](https://magenta.tensorflow.org/datasets/nsynth#files) is \"<i>a large-scale and high-quality dataset of annotated musical notes</i>\" <br>\n",
    "[Download](https://magenta.tensorflow.org/datasets/nsynth#files) train, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import re\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import time\n",
    "import collections\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('numpy version ',np.__version__)\n",
    "print('pandas version ',pd.__version__)\n",
    "print('librosa version ', librosa.__version__)\n",
    "print('re version ', re.__version__)\n",
    "# print('seaborn verrsion ', sns.__version__)\n",
    "print('scipy version ', scipy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruments & Sources\n",
    "### Instrument index\n",
    "\n",
    "| Index | ID   |\n",
    "|------|------|\n",
    "|   0  | bass|\n",
    "|   1  | brass|\n",
    "|   2  | flute|\n",
    "|   3  | guitar|\n",
    "|   4  | keyboard|\n",
    "|   5  | mallet|\n",
    "|   6  | organ|\n",
    "|   7  | reed|\n",
    "|   8  | string|\n",
    "|   9  | synth_lead|\n",
    "|   10  | vocal|\n",
    "\n",
    "### Source Index\n",
    "\n",
    "| Index | ID   |\n",
    "|------|------|\n",
    "|   0  | acoustic|\n",
    "|   1  | electronic|\n",
    "|   2  | synthetic|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store class names in array\n",
    "class_names=['bass', 'brass', 'flute', 'guitar', \n",
    "             'keyboard', 'mallet', 'organ', 'reed', \n",
    "             'string', 'synth_lead', 'vocal']\n",
    "#Store source names in array\n",
    "source_names=['acoustic', 'electronic', 'synthetic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anatomy of a Wave File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the features of a wave file by picking random samples for each instrument and illustrating the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick a random  wave file from the dataset\n",
    "pa_t_h = '/home/zaibachkhoa/Documents/Music-Genre-Classification-From-Audio-Files/Music_Instrument_Classification/dataset/valid/nsynth-valid/'\n",
    "bass_file = f'{pa_t_h}/audio/bass_electronic_018-047-075.wav'\n",
    "brass_file = f'{pa_t_h}/audio/brass_acoustic_006-031-050.wav'\n",
    "flute_file = f'{pa_t_h}/audio/flute_synthetic_000-035-127.wav'\n",
    "guitar_file = f'{pa_t_h}/audio/guitar_acoustic_010-086-100.wav'\n",
    "keyboard_file = f'{pa_t_h}/audio/keyboard_acoustic_004-041-100.wav'\n",
    "mallet_file = f'{pa_t_h}/audio/mallet_acoustic_056-065-050.wav'\n",
    "organ_file = f'{pa_t_h}/audio/organ_electronic_007-015-100.wav'\n",
    "reed_file =f'{pa_t_h}/audio/reed_acoustic_023-042-127.wav'\n",
    "string_file = f'{pa_t_h}/audio/string_acoustic_012-035-100.wav'\n",
    "synth_lead_file = f'{pa_t_h}/audio/flute_acoustic_002-093-075.wav'\n",
    "vocal_file = f'{pa_t_h}/audio/vocal_synthetic_003-030-050.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_files = [bass_file, brass_file, flute_file, guitar_file, keyboard_file, \n",
    "         mallet_file, organ_file, reed_file, string_file, synth_lead_file, vocal_file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waveform & Sampling Rate: [librosa.core.load](https://librosa.github.io/librosa/generated/librosa.core.load.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sound is a continous time signal that is usually represented by a wave <b>form</b>, this continuous signal is sampled and converted into a discrete time signal. <b>Sample Rate</b> is the number of samples of audio recorded per second. The sample rate determines the maximum audio frequency that can be reproduced, Indeed the maximum frequency that can be represented is half the sample rate. Most humans can hear sounds in the frequency of 20-20,000Hz and so most some sounds like CDs are sampled are 44,000Hz, that is to say in one second the analog signal is sampled 44,100. <br>\n",
    "\n",
    "Sources:<br>\n",
    "[Frequency Range of Human Hearing](https://hypertextbook.com/facts/2003/ChrisDAmbrose.shtml)<br>\n",
    "[7 Questions About Sample Rate](https://www.sweetwater.com/insync/7-things-about-sample-rate/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the audio as waveform y\n",
    "#store the sampling rate as s\n",
    "# To preserve the native sampling rate of the file, use sr=None\n",
    "y= []\n",
    "sr = []\n",
    "for file in sample_files:\n",
    "    y_out, sr_out = librosa.load(file, sr=None)\n",
    "    y.append(y_out)\n",
    "    sr.append(sr_out)\n",
    "for instrument, y_out, sr_out in zip(class_names, y, sr):\n",
    "    print(\"{} has {} samples with a sampling rate of {}\".format(instrument, np.size(y_out), sr_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harmonic & Percussive Component: [librosa.effects.hpss](https://librosa.github.io/librosa/generated/librosa.effects.hpss.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <b>percussion</b> instrument is simply instruments that you can bang on! Think of drums, gongs, xylophones, triangles, etc... A <b>harmonic</b> instrument is instrument that produces a series of sounds within which the fundamental frequency of each of them is an integral multiple of the lowest fundamental frequency. For harmonic instruments think of guitars, violions, trumpets, etc...<br>\n",
    "\n",
    "Sources:<br>\n",
    "[Percussion Instruments](https://ccrma.stanford.edu/CCRMA/Courses/152/percussion.html)<br>\n",
    "[IEV ref 801-30-04](http://www.electropedia.org/iev/iev.nsf/display?openform&ievref=801-30-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_harmonic= []\n",
    "y_percussive= []\n",
    "\n",
    "for sample in y:\n",
    "    y_harmonic.append(librosa.effects.hpss(sample)[0])\n",
    "    y_percussive.append(librosa.effects.hpss(sample)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j  in enumerate(y):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    librosa.display.waveshow(y_harmonic[i], sr=sr[i], alpha=0.25)\n",
    "    librosa.display.waveshow(y_percussive[i], sr=sr[i], color='r', alpha=0.5)\n",
    "    plt.legend(['Harmonic', 'Percussive'])\n",
    "    plt.title(\"Amplitude Envelope of Harmonic and Percussive Components for \" + class_names[i])\n",
    "    plt.savefig('plots/soundsAsArrays_'+str(class_names[i])+'.png')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beat & Tempo: [librosa.beat.beat_track](https://librosa.github.io/librosa/generated/librosa.beat.beat_track.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>tempo</b> is the rate of speed of a musical piece or passage indicated by one of a series of directions (such as largo, presto, or allegro) and often by an exact metronome marking.<br>\n",
    "Source:<br>\n",
    "[Merriam Webster](https://www.merriam-webster.com/dictionary/tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beat_frames = librosa.beat.beat_track(y=y[0], sr=sr[0])\n",
    "print(\"Tempo \", tempo)\n",
    "print(\"Beat frames \", beat_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a single note there's no such thing as a tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma Energy: [librosa.feature.chroma_cens](https://librosa.github.io/librosa/generated/librosa.feature.chroma_cens.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two pitches are perceived as similar in “color” if they differ by an octave. Based on this observation, a pitch can be separated into two components, which are referred to as tone height and chroma. Assuming the equal-tempered scale, the <b>chromas</b> correspond to the set {C, C♯, D, . . . , B} that consists of the twelve pitch spelling attributes as used in Western music notation. Thus, a chroma feature is represented by a 12 dimensional vector:<br>\n",
    "x = (x(1), x(2), ..., x(12))T<br>\n",
    "Where x(1) corresponds to chroma C, x(2) to chroma C# and so on. In the feature extraction step, a given audio signal is converted into a sequence of chroma features each expressing how the short-time energy of the signal is spread over the twelve chroma bands.<br>\n",
    "\n",
    "Source:<br>\n",
    "[Meinard Müller and Sebastian Ewert Chroma Toolbox: MATLAB implementations for extracting variants of chroma-based audio features In Proceedings of the International Conference on Music Information Retrieval (ISMIR), 2011.](http://ismir2011.ismir.net/papers/PS2-8.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromas = []\n",
    "for y_, sr_ in zip(y, sr):\n",
    "    chromas.append(librosa.feature.chroma_cens(y=y_, sr=sr_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chroma, instrument, i in zip(chromas,class_names, range(len(class_names))):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    librosa.display.specshow(chroma, y_axis='chroma', x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"CENS for \" + instrument)\n",
    "    plt.savefig('plots/ChromaEnergy_'+str(class_names[i])+'.png')\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel Spectrogram [librosa.feature.melspectrogram](https://librosa.github.io/librosa/generated/librosa.feature.melspectrogram.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>spectrogram</b> is a basic tool in audio spectral analysis and other fields. It has been applied extensively in speech analysis. The spectrogram can be defined as an intensity plot (usually on a log scale, such as dB) of the Short-Time Fourier Transform (STFT) magnitude. The STFT is simply a sequence of Fast Fourier Transforms (FFT) of windowed data segments, where the windows are usually allowed to overlap in time, typically by 25-50%. It is an important representation of audio data because human hearing is based on a kind of real-time spectrogram encoded by the cochlea of the inner ear. <br>The spectrogram has been used extensively in the field of computer music as a guide during the development of sound synthesis algorithms. When working with an appropriate synthesis model, matching the spectrogram often corresponds to matching the sound extremely well. In fact, spectral modeling synthesis (SMS) is based on synthesizing the short-time spectrum directly by some means.<br>\n",
    "\n",
    "The <b>mel</b> is a unit of pitch. The mel scale is a scale of pitches judged by listeners to be equal in distance one from another.\n",
    "\n",
    "\n",
    "Sources:<br>\n",
    "[Spectrograms](https://ccrma.stanford.edu/~jos/st/Spectrograms.html)<br>\n",
    "[Stevens, Stanley Smith; Volkmann; John & Newman, Edwin B. (1937). \"A scale for the measurement of the psychological magnitude pitch\"](https://archive.is/20130414065947/http://asadl.org/jasa/resource/1/jasman/v8/i3/p185_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms_mel = []\n",
    "\n",
    "for y_, sr_ in zip(y, sr):\n",
    "    # Passing through arguments to the Mel filters\n",
    "    spectrograms_mel.append(librosa.feature.melspectrogram(y=y_, sr=sr_, n_mels=128,fmax=8000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for S, instrument, i in zip(spectrograms_mel,class_names, range(len(class_names))):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    librosa.display.specshow(librosa.power_to_db(S,ref=np.max), \n",
    "                         y_axis='mel', fmax=8000, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(\"Mel spectrogram for \" + instrument)\n",
    "    plt.savefig('plots/mel_spectro_'+str(class_names[i])+'.png')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = []\n",
    "\n",
    "for y_, sr_ in zip(y, sr):\n",
    "    # Use left-aligned frames, instead of centered frames\n",
    "    D = np.abs(librosa.stft(y_))\n",
    "    spectro = librosa.amplitude_to_db(D, ref=np.max)\n",
    "    spectrograms.append(spectro)\n",
    "\n",
    "for S, instrument, i in zip(spectrograms,class_names, range(len(class_names))):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    librosa.display.specshow(S, \n",
    "                         y_axis='log', fmax=8000, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(\"Spectrogram for \" + instrument)\n",
    "    plt.savefig('plots/spectro_'+str(class_names[i])+'.png')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel-Frequency Cepstral Coefficients: [librosa.feature.mfcc](https://librosa.github.io/librosa/generated/librosa.feature.mfcc.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>mel-frequency cepstrum (MFC)</b> is a presentation of the short term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. MFC coefficients are the coefficients that make up an MFC. Using a mel scale means that the bands are equally scaled, which resembles the human hearing system more than linearly spaced based bands in a normal spectrum.<br>\n",
    "\n",
    "MFCCs are commonly derived as follows:<br>\n",
    "\n",
    "1) Take the Fourier transform of (a windowed excerpt of) a signal.<br>\n",
    "2) Map the powers of the spectrum obtained above onto the mel scale, using triangular overlapping windows.<br>\n",
    "3) Take the logs of the powers at each of the mel frequencies.<br>\n",
    "4) Take the discrete cosine transform of the list of mel log powers, as if it were a signal.<br>\n",
    "5) The MFCCs are the amplitudes of the resulting spectrum.<br>\n",
    "\n",
    "Sources:<br>\n",
    "[Speech Processing for Machine Learning](https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html)<br>\n",
    "[Wikipedia: Mel Frequency Cepstrum](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)<br>\n",
    "[Mel Frequency Cepstral Coefficient (MFCC) tutorial](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/#why-do-we-do-these-things)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = []\n",
    "for y_, sr_ in zip(y, sr):\n",
    "    mfccs.append(librosa.feature.mfcc(y=y_, sr=sr_, n_mfcc=13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mfcc, instrument,i in zip(mfccs,class_names,range(len(class_names))):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    librosa.display.specshow(mfcc, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('Mel-frequency cepstral coefficients for ' + instrument)\n",
    "    plt.savefig('plots/mfcc'+str(class_names[i])+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Centroid: [librosa.feature.spectral_centroid](https://librosa.github.io/librosa/generated/librosa.feature.spectral_centroid.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>spectral centroid</b> is commonly associated with the measure of the brightness of a sound. This measure is obtained by evaluating the “center of gravity” using the Fourier transform’s frequency and magnitude information. The individual centroid of a spectral frame is defined as the average frequency weighted by amplitudes, divided by the sum of the amplitudes.<br>\n",
    "\n",
    "Source:<br>\n",
    "[Spectral Centroid](https://www.cs.cmu.edu/~music/icm/slides/05-algorithmic-composition.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = []\n",
    "spectrograms = []\n",
    "phases = []\n",
    "\n",
    "for y_, sr_ in zip(y, sr):\n",
    "    centroids.append(librosa.feature.spectral_centroid(y=y_, sr=sr_))\n",
    "    spectrograms.append(librosa.magphase(librosa.stft(y=y_))[0])\n",
    "    phases.append(librosa.magphase(librosa.stft(y=y_))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a plot with log scaling on the y axis.\n",
    "for C, instrument, S, i in zip(centroids ,class_names, spectrograms, range(len(class_names))):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.semilogy(C.T, label='Spectral Centroid for ' + instrument)\n",
    "    plt.ylabel('Hz')\n",
    "    plt.xticks(np.arange(0,C.shape[-1],20))\n",
    "    plt.xlim([0, C.shape[-1]])\n",
    "    plt.xlabel('Frequency bins')\n",
    "    plt.legend()\n",
    "    #plt.subplot(2, 1, 2)\n",
    "    #librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),y_axis='log', x_axis='time')\n",
    "    #plt.title('log Power spectrogram for ' + instrument)\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig('plots/spectral_centroid'+str(class_names[i])+'.png')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Contrast: [librosa.feature.spectral_contrast](https://librosa.github.io/librosa/generated/librosa.feature.spectral_contrast.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Spectral contrast</b> is defined as the level difference between peaks and valleys in the spectrum. Octave-based Spectral Contrast considers the spectral peak, spectral valley and their difference in each sub-band.<br>\n",
    "Source: <br>\n",
    "[Jiang, Dan-Ning, Lie Lu, Hong-Jiang Zhang, Jian-Hua Tao, and Lian-Hong Cai. “Music type classification by spectral contrast feature.” In Multimedia and Expo, 2002. ICME‘02. Proceedings. 2002 IEEE International Conference on, vol. 1, pp. 113-116. IEEE, 2002.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.583.7201&rep=rep1&type=pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts = []\n",
    "for y_, sr_ in zip(y, sr):\n",
    "    contrasts.append(librosa.feature.spectral_contrast(y=y_, sr=sr_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contrast, instrument, i in zip(contrasts,class_names, range(len(class_names))):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    librosa.display.specshow(contrast,x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('Frequency bands')\n",
    "    plt.title('Spectral contrast for '+ instrument)\n",
    "    plt.savefig('plots/spectral_contrast_'+str(class_names[i])+'.png')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Rolloff Frequency: [librosa.feature.spectral_rolloff](https://librosa.github.io/librosa/generated/librosa.feature.spectral_rolloff.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the function docstring:<br>\n",
    "The <b>roll-off frequency</b> is defined for each frame as the center frequency for a spectrogram bin such that at least roll_percent (0.85 by default) of the energy of the spectrum in this frame is contained in this bin and the bins below. This can be used to, e.g., approximate the maximum (or minimum) frequency by setting roll_percent to a value close to 1 (or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolloffs = []\n",
    "for y_, sr_ in zip(y, sr):\n",
    "    rolloffs.append(librosa.feature.spectral_rolloff(y=y_, sr=sr_))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rolloff, instrument, i in zip(rolloffs,class_names, range(len(class_names))):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.semilogy(rolloff.T, label='Rolloff frequency for ' + instrument)\n",
    "    plt.ylabel('Hz')\n",
    "    plt.xlim([0, rolloff.shape[-1]])\n",
    "    plt.xlabel('Bins')\n",
    "    plt.xticks(np.arange(0,rolloff.shape[-1],20))\n",
    "    plt.title(\"Rolloff Frequency for \"+ class_names[i])\n",
    "    plt.savefig('plots/rolloff_freq'+str(class_names[i])+'.png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Crossings: [librosa.core.zero_crossings](https://librosa.github.io/librosa/generated/librosa.core.zero_crossings.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the zero-crossings of a signal y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_crossings = []\n",
    "for y_ in y:\n",
    "    z = librosa.zero_crossings(y_)\n",
    "    #Find number of zero crossings\n",
    "    z_crossings.append(np.sum(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Crossing Rate: [librosa.feature.zero_crossing_rate](https://librosa.github.io/librosa/generated/librosa.feature.zero_crossing_rate.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the zero-crossing rate of an audio time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zrates = []\n",
    "for y_ in y:\n",
    "    zrates.append(librosa.feature.zero_crossing_rate(y=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zrate, instrument, i in zip(zrates,class_names, range(len(class_names))):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.semilogy(zrate.T, label='Fraction')\n",
    "    plt.ylabel('Fraction Per Frame')\n",
    "    plt.xlabel('Bins')\n",
    "    plt.xticks(np.arange(0, rolloff.shape[-1], 20))\n",
    "    plt.xlim([0, rolloff.shape[-1]])\n",
    "    plt.title(\"Zero crossing rate for \"+ instrument)\n",
    "    plt.legend()\n",
    "    plt.savefig('plots/zerocross_'+str(class_names[i])+'.png')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zrate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Chroma Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_means = []\n",
    "chroma_stds = []\n",
    "\n",
    "for chroma in chromas:\n",
    "    chroma_means.append(np.mean(chroma, axis=1))\n",
    "    chroma_stds.append(np.std(chroma, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Background on octaves and equal temperament scale](https://en.wikipedia.org/wiki/Equal_temperament)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define octaves\n",
    "octave=['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chroma_mean,  instrument in zip(chroma_means,class_names):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(\"Mean Chroma Energy for \"+ instrument)\n",
    "    sns.barplot(x=octave, y=chroma_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chroma_std, instrument in zip(chroma_stds,class_names):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(\"Mean Chroma Energy for \"+ instrument)\n",
    "    sns.barplot(x=octave, y=chroma_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Mel-Frequency Cepstral Coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_means = []\n",
    "mfcc_stds = []\n",
    "coefficients = []\n",
    "\n",
    "for mfcc in mfccs:\n",
    "    mfcc_means.append(np.mean(mfcc,axis=1))\n",
    "    mfcc_stds.append(np.std(mfcc,axis=1))\n",
    "    coefficients.append(np.arange(0,mfcc.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mfcc_mean, coefficient, instrument in zip(mfcc_means, coefficients,class_names):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(\"Mean Mel-Frequency Cepstral Coefficients for \" + instrument)\n",
    "    sns.barplot(x=coefficient, y=mfcc_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mfcc_std, coefficient, instrument in zip(mfcc_stds, coefficients,class_names):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(\"Standard Deviation Mel-Frequency Cepstral Coefficients for \" + instrument)\n",
    "    sns.barplot(x=coefficient, y=mfcc_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Centroid Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_means = []\n",
    "centroid_stds = []\n",
    "centroid_skews = []\n",
    "\n",
    "for i in range(len(centroids)):\n",
    "    centroid_means.append(np.mean(centroids[i]))\n",
    "    centroid_stds.append(np.std(centroids[i]))\n",
    "    centroid_skews.append(scipy.stats.skew(centroids[i], axis=1)[0])\n",
    "    print(\"Centroid mean of {} is {}\".format(class_names[i], centroid_means[i]))\n",
    "    print(\"Centroid standard deviation of {} is \".format(class_names[i], centroid_stds[i]))\n",
    "    print(\"Centroid skewness of {} is {} \\n\".format(class_names[i], centroid_skews[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Contrast Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_means= []\n",
    "contrast_stds= []\n",
    "\n",
    "for C in contrasts:\n",
    "    contrast_means.append(np.mean(C, axis=1))\n",
    "    contrast_stds.append(np.mean(C, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C, contrast, instrument in zip(contrast_means, contrasts,class_names):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    n_constrast= np.arange(0, contrast.shape[0])\n",
    "    plt.title(\"Mean Spectral Contrast for \" + instrument)\n",
    "    sns.barplot(x=n_constrast, y= C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C, contrast, instrument in zip(contrast_stds, contrasts,class_names):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    n_constrast= np.arange(0, contrast.shape[0])\n",
    "    plt.title(\"Standard Deviation Spectral Contrast \" + instrument)\n",
    "    sns.barplot(x=n_constrast, y= C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Rolloff Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolloff_means = []\n",
    "rolloff_stds = []\n",
    "rolloff_skews = []\n",
    "\n",
    "for i in range(len(rolloffs)):\n",
    "    rolloff_means.append(np.mean(rolloffs[i]))\n",
    "    rolloff_stds.append(np.std(rolloffs[i]))\n",
    "    rolloff_skews.append(scipy.stats.skew(rolloffs[i], axis=1)[0])\n",
    "    print(\"Rolloff mean of {} is {}\".format(class_names[i], rolloff_means[i]))\n",
    "    print(\"Rolloff standard deviation of {} is \".format(class_names[i], rolloff_stds[i]))\n",
    "    print(\"Rolloff skewness of {} is {} \\n\".format(class_names[i], rolloff_skews[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Crossing Rate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zrate_means = []\n",
    "zrate_stds = []\n",
    "zrate_skews = []\n",
    "\n",
    "for i in range(len(zrates)):\n",
    "    zrate_means.append(np.mean(zrates[i]))\n",
    "    zrate_stds.append(np.std(zrates[i]))\n",
    "    zrate_skews.append(scipy.stats.skew(zrates[i], axis=1)[0])\n",
    "    print(\"Zero Crossing mean of {} is {}\".format(class_names[i], zrate_means[i]))\n",
    "    print(\"Zero Crossing standard deviation of {} is \".format(class_names[i], zrate_stds[i]))\n",
    "    print(\"Zero Crossing skewness of {} is {} \\n\".format(class_names[i], zrate_skews[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
